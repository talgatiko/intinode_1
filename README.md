# intinode_1
 концепцию intinode — механизма ленивой загрузки файлов по хешу на уровне ядра Linux. Он позволяет хранить в контейнерных образах, образах ВМ, AppImage, Flatpak и Snap только метаданные, а сами файлы загружать по требованию в общий кеш.
Интернет-иноды: как избавить облака от 90% мёртвых байтов





TL;DR: Представляем концепцию intinode — механизма ленивой загрузки файлов по хешу на уровне ядра Linux. Он позволяет хранить в контейнерных образах, образах ВМ, AppImage, Flatpak и Snap только метаданные, а сами файлы загружать по требованию в общий кеш. В облаке — экономия от 90% дискового пространства, на ноутбуке — меньше SSD-трафика и быстрее запуск приложений. И всё это — без единой строчки изменений в прикладном коде.



Проблема: мы платим за одни и те же байты тысячи раз

Представьте типичную инфраструктуру современного облака:





5000 контейнеров: Nginx, Python-микросервисы, Kafka-клиенты.



2000 виртуальных машин: Ubuntu, CentOS, Windows Server.



Ещё сотни AppImage-приложений на рабочих станциях разработчиков.

Что у них общего?
 Тысячи копий одних и тех же файлов:





/usr/bin/python3.10 — весит 6 МБ, но хранится 8000 раз → 48 ГБ мёртвых данных.



/lib/x86_64-linux-gnu/libc-2.35.so — 2 МБ × 10 000 копий → 20 ГБ.



Базовые слои Docker-образов (ubuntu:22.04) — повторяются в 90% контейнеров.

По данным исследований Microsoft и AWS, до 85–90% данных в cloud-хранилищах — дубликаты. Это не просто «избыток» — это:





Дорогие SSD, которые простаивают.



Сетевой трафик, который можно было бы направить на полезную работу.



Задержки при запуске: пока образ весом 1 ГБ выкачивается из registry, пользователь ждёт.



Ограниченная плотность размещения: меньше контейнеров на ноду → выше стоимость инфраструктуры.

Существующие подходы — реактивные, а не проактивные:





Deduplication в ZFS/btrfs — работает после записи, тратя CPU и время.



Пользовательские скрипты — не масштабируются.



OverlayFS + shared layers — помогают, но не решают проблему между разными образами или ВМ.

Нужно архитектурное решение, а не патч.



Идея: файл — это его содержимое, а не имя

В 1970-х файл был «кусочком данных по пути /etc/passwd».
 Сегодня, в эпоху immutable infrastructure, файл — это неизменяемая сущность, идентифицируемая только своим содержимым.

Эту парадигму уже используют:





Git — объекты по хешу.



IPFS — контентная адресация.



NixOS — каждая версия пакета — уникальный путь по хешу.



Docker layers — но только внутри одного образа.

Мы делаем следующий шаг: переносим content-addressable storage в ядро ОС.

Знакомьтесь: интернет-инода (intinode).



Что такое intinode?

intinode — это обычный файл, лежащий в той же директории, где должен быть оригинальный файл. Его содержимое начинается с магической строки:
"intinode" :

intinode {"digest":"sha256:abc123...","size":12345678,"urls":["oci://registry/layer@sha256:abc123...","s3://global-cache/sha256/abc123..."]}


Он:





Занимает менее 200 байт.



Может называться как угодно (python3, libc.so.6, app.AppImage).



Полностью совместим с tar, rsync, git — это просто файл.

Когда приложение (или execve()) читает такой файл, ядро Linux (с модулем intinode.ko) выполняет:





Быструю проверку: читает первые 8 байт → если "intinode ", значит это видимо intinode, далее:



Парсинг JSON: извлекает digest, size, urls.



Поиск в кеше: проверяет наличие /var/cache/intinode/sha256/abc123....



Если файл есть — отдаёт напрямую (с поддержкой mmap() и execve()).



Если нет — отправляет запрос демону intinode-fetchd и возвращает EAGAIN (неблокирующий режим).

Демон intinode-fetchd:





Работает в пользовательском пространстве (минимизация кода в ядре).



Ищет файл по urls (OCI registry, S3, HTTP, P2P).



Проверяет и размер, и SHA-256 — двойная защита от подмены.



Сохраняет в кеш и уведомляет ядро.

Следующий вызов — уже работает с кешем.
 Приложение даже не замечает разницы.



Архитектура: ядро, демон, кеш





Почему это работает





Совместимость: обычные файлы — обычные файлы. Только intinode — особые.



Безопасность: подделка требует коллизии SHA-256 и точного совпадения размера. На 2025 год — теоретически невозможно.



Производительность: кеш на SSD, доступ за 50–100 мкс. Горячие файлы — в RAM.



Масштаб: один кеш на хост → все контейнеры, ВМ, AppImage делят файлы.



Где это применимо? Конкретные сценарии

1. Образ веб-браузера: от гигабайтов к мегабайтам

Представьте популярный браузер в формате AppImage. Сегодня его образ весит 800 МБ–1.2 ГБ из-за включённых библиотек (Qt, Chromium, Python). Большая часть этих файлов уже есть в системе или в других приложениях.

С intinode:





Бинарные файлы браузера заменяются на intinode-описатели.



Общие библиотеки (Qt, libc) ссылаются на хеши из глобального кеша.



Размер образа сокращается до 50–70 МБ (только уникальные файлы + метаданные).

Результат для пользователя:





Скачивание браузера за 5–10 секунд вместо 5–10 минут.



Меньше места на SSD.



Обновления — только изменённые файлы (10–20 МБ вместо 800 МБ).



2. Облачный кластер: 1000 контейнеров на одной ноде

Ситуация:
 В Kubernetes-кластере развёрнуто 500 копий веб-сервера на Nginx и 500 экземпляров Python-бэкенда. Каждый образ весит 800 МБ.

Как это работает с intinode:





Образы хранятся в registry как thin-manifests с метаданными вместо полных файлов.



При старте пода: 





Kubelet скачивает manifest (50 КБ вместо 800 МБ).



Ядро загружает /usr/sbin/nginx и /usr/bin/python3 в общий кеш.



Все 1000 контейнеров используют один экземпляр каждого бинарника.

Результат:





Хранение на ноде: 1.5 ГБ вместо 800 ГБ.



Сетевой трафик: 50 КБ/контейнер вместо 800 МБ.



Плотность: 1000 контейнеров на ноду вместо 150.



3. Виртуальная машина: быстрый старт «худосочного» образа

Ситуация:
 Образ Ubuntu Cloud Image весит 2.5 ГБ. В облаке нужно запустить 100 ВМ для CI/CD-задач.

Как это работает с intinode:





Образ преобразуется в skinny-версию, содержащую только метаданные критических файлов.



При первом старте ВМ: 





Загружаются только ядро, initramfs и базовые утилиты.



Остальные файлы (gcc, git, python) подгружаются по мере вызова.



Общий кеш на гипервизоре: /var/cache/intinode/ разделяется между всеми ВМ.

Результат:





Время старта ВМ: в разы быстрее.



Хранение на гипервизоре: ~20 ГБ вместо 250 ГБ для 100 ВМ.



Live migration: переносится только состояние, а не весь образ.



Почему не FUSE?

FUSE — удобен для прототипирования, но:





Медленный: каждый read() — контекстный переключатель в userspace.



Ненадёжный для execve(): ядро требует, чтобы исполняемый файл был доступен полностью и сразу.



Нет поддержки mmap() на уровне страниц — критично для браузеров и тяжелых приложений.

intinode работает внутри VFS, как настоящая файловая система:





Поддержка всех системных вызовов.



Прямой доступ к page cache.



Возможность отображения через mmap().



Экономика: цифры, которые убеждают









Показатель



До intinode



После intinode



Эффект





Размер образа контейнера



1.0 ГБ



50–100 МБ



×10 меньше





Время запуска



30 сек



2–5 сек



×6–15 быстрее





Хранение на 1000 контейнерах



1000 ГБ



~100 ГБ



экономия 90%





Сетевой трафик при старте



100%



10–20%



экономия 80–90%





Плотность размещения



10 контейнеров/нода



15–20



+50–100%





Экологический след (CO₂)



100%



15–20%



-80%

Для крупного облака (10 000 серверов):





Годовая экономия на дисках: сотни тысяч долларов.



Дополнительная выручка: +30–40% рабочих нагрузок без новых серверов.



Экология: меньше дисков → меньше энергии → меньше CO₂.



План внедрения: от концепции к реальности

Как системный аналитик с опытом в облачных архитектурах, вижу следующий путь реализации:

1. Создание альянса заинтересованных сторон

Концепция требует координации:





Провайдеры облаков (Яндекс Облако, VK Cloud, Selectel) — получают прямую экономию.



Дистрибутивы Linux (Альт, РедОС, OpenSUSE) — интеграция в пакетную систему.



Разработчики ПО — поддержка в AppImage, Flatpak, Snap.



Сообщество ядра Linux — критически важна для масштабирования.

2. Разработка через open source

Несмотря на то, что российские ИТ-компании могли бы реализовать проект внутренними силами за несколько месяцев, есть стратегические причины выбрать open source путь:





Интеграция с ядром Linux требует прохождения upstream-ревью. Закрытая реализация не будет принята.



Доверие: только публичный аудит кода гарантирует безопасность при работе с критическими системными вызовами.



Экосистема: решение должно работать не только в одном облаке, а везде — от ноутбука разработчика до гипермасштабируемых кластеров.

3. Этапы внедрения





PoC: создание минимальной рабочей версии для демонстрации экономии.



Стандартизация: предложение расширения OCI-спецификации для поддержки thin-manifests.



Интеграция: патчи для containerd, BuildKit, QEMU, systemd.



Массовое внедрение: поддержка в популярных дистрибутивах и облаках.

4. Ролевая модель





Российские компании: фокус на PoC, интеграцию с внутренними облаками, пилотные проекты.



Международное сообщество: стандартизация через OCI и Linux Foundation, поддержка в upstream-ядре.



Независимые разработчики: инструменты для конвертации образов, GUI-утилиты для десктопа.



Стандартизация и экосистема



Будущее: файловая система без имён

Сегодня мы привыкли, что файл — это /usr/bin/python3.
 Завтра — файл будет запрашиваться по хешу, как в распределённых системах.

intinode — первый шаг к миру, где:





Имена файлов — лишь удобство для людей.



Содержимое — единственный источник истины.



Хранение — децентрализовано, дедуплицировано, безопасно.

 Это — логическое развитие immutable infrastructure.



Заключение: системное решение для системной проблемы

Интернет-иноды — это не «ещё один кеш». Это фундаментальный сдвиг:





От имён к содержимому.



От локального хранения к глобальному.



От избыточности к эффективности.

Как аналитик, наблюдающий за развитием облачных технологий последние 10 лет, утверждаю: мы достигли точки, когда традиционные подходы к хранению файлов тормозят развитие инфраструктуры. Оптимизация на уровне приложений исчерпала себя. Нужны изменения на уровне операционной системы.

Почему именно сейчас?





SSD-накопители стали основным типом хранения — их ресурс ограничен количеством записей.



Контейнеризация достигла зрелости, но рост образов стал узким местом.

Российские компании обладают всеми компетенциями для реализации этой концепции. Но её успех зависит не от одного игрока, а от экосистемы.

Вместе мы можем создать инфраструктуру, где хранение данных оптимизировано по физическим законам, а не по историческим артефактам файловых систем 1970-х годов.

Файл — это не путь. Файл — это его содержимое.



Автор: системный аналитик 
Цель публикации: привлечь внимание к системной проблеме и обсудить предложенное архитектурное решение.





P.S. Концепция intinode находится на стадии предложения. Для перехода к реализации необходимы обсуждения с сообществом разработчиков ядра Linux, инженерами cloud-провайдеров и экспертами по стандартизации. Готов к диалогу и совместной проработке деталей.

